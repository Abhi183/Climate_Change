{"cells":[{"cell_type":"code","execution_count":null,"id":"5e39212c","metadata":{"id":"5e39212c"},"outputs":[],"source":["import os\n","import numpy as np \n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import math\n","from sklearn.cluster import KMeans \n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler\n","from matplotlib import pyplot as plt\n","from matplotlib import animation, colors\n","from sklearn.cluster import KMeans\n","from sklearn import preprocessing as sk_preprocessing\n","from sklearn.metrics import accuracy_score #scoring\n","from sklearn.metrics import confusion_matrix\n","from sklearn.decomposition import PCA\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras import datasets, layers, models\n","from keras.callbacks import EarlyStopping\n","from tensorflow.keras.callbacks import TensorBoard"]},{"cell_type":"code","execution_count":null,"id":"6e87e4f9","metadata":{"id":"6e87e4f9"},"outputs":[],"source":["pressure = '/Users/votri/Downloads/DSDA 385 Machine Learning/Final Project - Climate Change/Pressure/MinMaxNormWithLabel/'\n","\n","wind = '/Users/votri/Downloads/DSDA 385 Machine Learning/Final Project - Climate Change/CESMU200/MinMaxNormWithLabel/'\n","\n","# Get the list of subfolders\n","subfolders = [subfolder for subfolder in os.listdir(pressure) if os.path.isdir(os.path.join(pressure, subfolder))]\n","\n","dfs_pressure = []\n","dfs_wind = []\n","reshaped_arrays = []\n","folder_names = []\n","\n","for subfolder in subfolders:\n","    pressure_path = os.path.join(pressure, subfolder)\n","    wind_path = os.path.join(wind, subfolder)\n","    files = [f for f in os.listdir(pressure_path) if f.endswith('.csv')]\n","    for file in files:\n","        # pressure data\n","        pressure_file_path = os.path.join(pressure_path, file)\n","        df_pressure = pd.read_csv(pressure_file_path, header=None)\n","        df_pressure = np.array(df_pressure)\n","        dfs_pressure.append(df_pressure)\n","        \n","        # wind data\n","        wind_file_path = os.path.join(wind_path, file)\n","        df_wind = pd.read_csv(wind_file_path, header=None)\n","        df_wind = np.array(df_wind)\n","        dfs_wind.append(df_wind)\n","        \n","        # stack 2 arrays\n","        df = np.dstack((df_pressure, df_wind))\n","        (h,w,c) = df.shape\n","        df_2D = df.reshape(h*w,c) # reshape df to 2D\n","        \n","        reshaped_array = np.reshape(df, (1,-1)) # Reshape the dataframe into a 1D array with 225 attributes\n","        reshaped_arrays.append(reshaped_array)  # Append the reshaped array to the list\n","        \n","        folder_names.append(subfolder) # Save the class of the image\n","        \n","# Concatenate the reshaped arrays into a single array\n","concatenated_array = np.concatenate(reshaped_arrays, axis=0)\n","\n","# Convert the concatenated array into a dataframe\n","result_df = pd.DataFrame(concatenated_array)\n","result_df['Class'] = folder_names"]},{"cell_type":"code","execution_count":null,"id":"8eb99cf0","metadata":{"scrolled":true,"id":"8eb99cf0","outputId":"ee95682f-d653-48ab-a18f-01bc50ee91ca"},"outputs":[{"name":"stdout","output_type":"stream","text":["            0         1         2         3         4         5         6  \\\n","0    0.139692  0.000000  0.139077  0.000000  0.137846  0.000000  0.137231   \n","1    0.475692  0.222222  0.473846  0.218182  0.471385  0.196429  0.468923   \n","2    0.248615  0.106383  0.243692  0.083333  0.240000  0.062500  0.237538   \n","3    0.248615  0.106383  0.243692  0.083333  0.240000  0.062500  0.237538   \n","4    0.293538  0.208333  0.284923  0.163265  0.278154  0.120000  0.272615   \n","..        ...       ...       ...       ...       ...       ...       ...   \n","732  0.844923  0.400000  0.857231  0.312500  0.872615  0.272727  0.886154   \n","733  0.912615  0.205882  0.915692  0.228571  0.923692  0.184211  0.929846   \n","734  0.931077  0.305556  0.933538  0.315068  0.931692  0.328767  0.931692   \n","735  0.868923  0.603774  0.875077  0.509091  0.880000  0.413793  0.883692   \n","736  0.856000  0.028986  0.864000  0.014706  0.874462  0.058824  0.876923   \n","\n","            7         8         9  ...       441       442       443  \\\n","0    0.000000  0.137231  0.023256  ...  0.388889  0.082462  0.381818   \n","1    0.157895  0.465846  0.135593  ...  0.500000  0.425846  0.483871   \n","2    0.041667  0.235692  0.040816  ...  0.537037  0.222769  0.555556   \n","3    0.041667  0.235692  0.040816  ...  0.537037  0.222769  0.555556   \n","4    0.061224  0.268923  0.020408  ...  0.421053  0.221538  0.421053   \n","..        ...       ...       ...  ...       ...       ...       ...   \n","732  0.264706  0.890462  0.277778  ...  0.367347  0.889231  0.384615   \n","733  0.119048  0.932308  0.111111  ...  0.516129  0.926154  0.444444   \n","734  0.328767  0.931077  0.333333  ...  0.408451  0.921846  0.352113   \n","735  0.366667  0.884923  0.317460  ...  0.455882  0.892923  0.477612   \n","736  0.119403  0.873846  0.164179  ...  0.210526  0.935385  0.214286   \n","\n","          444       445       446       447       448       449  Class  \n","0    0.086154  0.400000  0.092308  0.415094  0.102769  0.431373     CL  \n","1    0.429538  0.467742  0.435077  0.459016  0.443077  0.423729     CL  \n","2    0.232615  0.555556  0.246154  0.566038  0.264615  0.588235     CL  \n","3    0.232615  0.555556  0.246154  0.566038  0.264615  0.588235     CL  \n","4    0.229538  0.421053  0.240000  0.438596  0.253538  0.454545     CL  \n","..        ...       ...       ...       ...       ...       ...    ...  \n","732  0.896000  0.370370  0.899077  0.357143  0.900308  0.383333   NROI  \n","733  0.926769  0.375000  0.927385  0.328125  0.928615  0.265625   NROI  \n","734  0.923077  0.323944  0.920615  0.291667  0.921846  0.250000   NROI  \n","735  0.898462  0.507463  0.904000  0.500000  0.913846  0.476190   NROI  \n","736  0.933538  0.236364  0.931077  0.254545  0.927385  0.240741   NROI  \n","\n","[737 rows x 451 columns]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>440</th>\n","      <th>441</th>\n","      <th>442</th>\n","      <th>443</th>\n","      <th>444</th>\n","      <th>445</th>\n","      <th>446</th>\n","      <th>447</th>\n","      <th>448</th>\n","      <th>449</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>737.000000</td>\n","      <td>737.000000</td>\n","      <td>737.000000</td>\n","      <td>737.000000</td>\n","      <td>737.000000</td>\n","      <td>737.000000</td>\n","      <td>737.000000</td>\n","      <td>737.000000</td>\n","      <td>737.000000</td>\n","      <td>737.000000</td>\n","      <td>...</td>\n","      <td>737.000000</td>\n","      <td>737.000000</td>\n","      <td>737.000000</td>\n","      <td>737.000000</td>\n","      <td>737.000000</td>\n","      <td>737.000000</td>\n","      <td>737.000000</td>\n","      <td>737.000000</td>\n","      <td>737.000000</td>\n","      <td>737.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.653576</td>\n","      <td>0.304457</td>\n","      <td>0.652917</td>\n","      <td>0.293300</td>\n","      <td>0.652001</td>\n","      <td>0.282113</td>\n","      <td>0.650932</td>\n","      <td>0.271847</td>\n","      <td>0.649845</td>\n","      <td>0.263561</td>\n","      <td>...</td>\n","      <td>0.643169</td>\n","      <td>0.476756</td>\n","      <td>0.647061</td>\n","      <td>0.472584</td>\n","      <td>0.652169</td>\n","      <td>0.468764</td>\n","      <td>0.658171</td>\n","      <td>0.465328</td>\n","      <td>0.664773</td>\n","      <td>0.463245</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.259836</td>\n","      <td>0.283046</td>\n","      <td>0.261524</td>\n","      <td>0.281538</td>\n","      <td>0.262980</td>\n","      <td>0.278370</td>\n","      <td>0.264169</td>\n","      <td>0.276129</td>\n","      <td>0.265151</td>\n","      <td>0.274591</td>\n","      <td>...</td>\n","      <td>0.279557</td>\n","      <td>0.277604</td>\n","      <td>0.279201</td>\n","      <td>0.276394</td>\n","      <td>0.278348</td>\n","      <td>0.275974</td>\n","      <td>0.277009</td>\n","      <td>0.276022</td>\n","      <td>0.275190</td>\n","      <td>0.277787</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.483692</td>\n","      <td>0.062500</td>\n","      <td>0.480000</td>\n","      <td>0.056604</td>\n","      <td>0.478769</td>\n","      <td>0.053333</td>\n","      <td>0.473846</td>\n","      <td>0.051282</td>\n","      <td>0.468308</td>\n","      <td>0.041667</td>\n","      <td>...</td>\n","      <td>0.447385</td>\n","      <td>0.265306</td>\n","      <td>0.451077</td>\n","      <td>0.254902</td>\n","      <td>0.459692</td>\n","      <td>0.254902</td>\n","      <td>0.467692</td>\n","      <td>0.256410</td>\n","      <td>0.478154</td>\n","      <td>0.250000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.719385</td>\n","      <td>0.211538</td>\n","      <td>0.721231</td>\n","      <td>0.188679</td>\n","      <td>0.721231</td>\n","      <td>0.181818</td>\n","      <td>0.716923</td>\n","      <td>0.163636</td>\n","      <td>0.710769</td>\n","      <td>0.156250</td>\n","      <td>...</td>\n","      <td>0.709538</td>\n","      <td>0.518072</td>\n","      <td>0.713231</td>\n","      <td>0.500000</td>\n","      <td>0.719385</td>\n","      <td>0.500000</td>\n","      <td>0.726154</td>\n","      <td>0.488372</td>\n","      <td>0.736000</td>\n","      <td>0.472727</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.882462</td>\n","      <td>0.514286</td>\n","      <td>0.888615</td>\n","      <td>0.490566</td>\n","      <td>0.894769</td>\n","      <td>0.486486</td>\n","      <td>0.899692</td>\n","      <td>0.437500</td>\n","      <td>0.901538</td>\n","      <td>0.424242</td>\n","      <td>...</td>\n","      <td>0.903385</td>\n","      <td>0.687500</td>\n","      <td>0.910154</td>\n","      <td>0.690141</td>\n","      <td>0.916308</td>\n","      <td>0.681319</td>\n","      <td>0.918769</td>\n","      <td>0.674157</td>\n","      <td>0.922462</td>\n","      <td>0.673077</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>0.995077</td>\n","      <td>1.000000</td>\n","      <td>0.992000</td>\n","      <td>1.000000</td>\n","      <td>0.988308</td>\n","      <td>1.000000</td>\n","      <td>0.986462</td>\n","      <td>1.000000</td>\n","      <td>0.987692</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 450 columns</p>\n","</div>"],"text/plain":["              0           1           2           3           4           5    \\\n","count  737.000000  737.000000  737.000000  737.000000  737.000000  737.000000   \n","mean     0.653576    0.304457    0.652917    0.293300    0.652001    0.282113   \n","std      0.259836    0.283046    0.261524    0.281538    0.262980    0.278370   \n","min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n","25%      0.483692    0.062500    0.480000    0.056604    0.478769    0.053333   \n","50%      0.719385    0.211538    0.721231    0.188679    0.721231    0.181818   \n","75%      0.882462    0.514286    0.888615    0.490566    0.894769    0.486486   \n","max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n","\n","              6           7           8           9    ...         440  \\\n","count  737.000000  737.000000  737.000000  737.000000  ...  737.000000   \n","mean     0.650932    0.271847    0.649845    0.263561  ...    0.643169   \n","std      0.264169    0.276129    0.265151    0.274591  ...    0.279557   \n","min      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n","25%      0.473846    0.051282    0.468308    0.041667  ...    0.447385   \n","50%      0.716923    0.163636    0.710769    0.156250  ...    0.709538   \n","75%      0.899692    0.437500    0.901538    0.424242  ...    0.903385   \n","max      1.000000    1.000000    1.000000    1.000000  ...    0.995077   \n","\n","              441         442         443         444         445         446  \\\n","count  737.000000  737.000000  737.000000  737.000000  737.000000  737.000000   \n","mean     0.476756    0.647061    0.472584    0.652169    0.468764    0.658171   \n","std      0.277604    0.279201    0.276394    0.278348    0.275974    0.277009   \n","min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n","25%      0.265306    0.451077    0.254902    0.459692    0.254902    0.467692   \n","50%      0.518072    0.713231    0.500000    0.719385    0.500000    0.726154   \n","75%      0.687500    0.910154    0.690141    0.916308    0.681319    0.918769   \n","max      1.000000    0.992000    1.000000    0.988308    1.000000    0.986462   \n","\n","              447         448         449  \n","count  737.000000  737.000000  737.000000  \n","mean     0.465328    0.664773    0.463245  \n","std      0.276022    0.275190    0.277787  \n","min      0.000000    0.000000    0.000000  \n","25%      0.256410    0.478154    0.250000  \n","50%      0.488372    0.736000    0.472727  \n","75%      0.674157    0.922462    0.673077  \n","max      1.000000    0.987692    1.000000  \n","\n","[8 rows x 450 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["print(result_df)\n","result_df.describe()"]},{"cell_type":"code","execution_count":null,"id":"aac4950f","metadata":{"scrolled":true,"id":"aac4950f","outputId":"a3be6a8c-7e13-4f37-e512-41db30119c6d"},"outputs":[{"name":"stdout","output_type":"stream","text":["COL     327\n","CL      178\n","COH     161\n","NROI     71\n","Name: Class, dtype: int64\n"]}],"source":["counts = result_df['Class'].value_counts()\n","print(counts)"]},{"cell_type":"code","execution_count":null,"id":"a0f7f8e2","metadata":{"scrolled":false,"id":"a0f7f8e2","outputId":"a7da671c-fe86-4b35-fb47-ab06edd7430f"},"outputs":[{"name":"stdout","output_type":"stream","text":["0      0\n","1      0\n","2      0\n","3      0\n","4      0\n","      ..\n","732    1\n","733    1\n","734    1\n","735    1\n","736    1\n","Name: Class, Length: 737, dtype: int64\n"]}],"source":["X = result_df.drop('Class', axis = 1)\n","Y = result_df['Class']\n","\n","Y_numerized = Y.replace({'CL': 0, 'COL' : 2, 'COH': 3, 'NROI': 1})\n","print(Y_numerized)"]},{"cell_type":"code","execution_count":null,"id":"259558db","metadata":{"id":"259558db","outputId":"45070a49-1a78-427f-c368-57088831e99c"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[[[0.139692 0.      ]\n","   [0.139077 0.      ]\n","   [0.137846 0.      ]\n","   ...\n","   [0.150154 0.036364]\n","   [0.153846 0.018868]\n","   [0.156923 0.019608]]\n","\n","  [[0.136    0.      ]\n","   [0.134154 0.      ]\n","   [0.131692 0.      ]\n","   ...\n","   [0.138462 0.018182]\n","   [0.142154 0.      ]\n","   [0.146462 0.      ]]\n","\n","  [[0.132308 0.025641]\n","   [0.129846 0.025641]\n","   [0.126154 0.      ]\n","   ...\n","   [0.124923 0.      ]\n","   [0.129846 0.      ]\n","   [0.134769 0.      ]]\n","\n","  ...\n","\n","  [[0.150154 0.358974]\n","   [0.138462 0.384615]\n","   [0.125538 0.384615]\n","   ...\n","   [0.069538 0.309091]\n","   [0.075692 0.301887]\n","   [0.084308 0.313725]]\n","\n","  [[0.158769 0.384615]\n","   [0.146462 0.410256]\n","   [0.133538 0.410256]\n","   ...\n","   [0.076923 0.345455]\n","   [0.081846 0.358491]\n","   [0.091692 0.372549]]\n","\n","  [[0.167385 0.410256]\n","   [0.155692 0.410256]\n","   [0.142769 0.435897]\n","   ...\n","   [0.086154 0.4     ]\n","   [0.092308 0.415094]\n","   [0.102769 0.431373]]]\n","\n","\n"," [[[0.475692 0.222222]\n","   [0.473846 0.218182]\n","   [0.471385 0.196429]\n","   ...\n","   [0.446769 0.016129]\n","   [0.448    0.016393]\n","   [0.450462 0.016949]]\n","\n","  [[0.473846 0.148148]\n","   [0.470769 0.127273]\n","   [0.467692 0.107143]\n","   ...\n","   [0.437538 0.      ]\n","   [0.44     0.      ]\n","   [0.443077 0.      ]]\n","\n","  [[0.468923 0.074074]\n","   [0.464615 0.054545]\n","   [0.460308 0.035714]\n","   ...\n","   [0.428308 0.      ]\n","   [0.430769 0.      ]\n","   [0.435692 0.      ]]\n","\n","  ...\n","\n","  [[0.427077 0.314815]\n","   [0.423385 0.345455]\n","   [0.419077 0.357143]\n","   ...\n","   [0.402462 0.33871 ]\n","   [0.408615 0.327869]\n","   [0.417846 0.305085]]\n","\n","  [[0.432615 0.333333]\n","   [0.428923 0.381818]\n","   [0.426462 0.392857]\n","   ...\n","   [0.414154 0.403226]\n","   [0.420308 0.393443]\n","   [0.428923 0.372881]]\n","\n","  [[0.436923 0.37037 ]\n","   [0.435692 0.418182]\n","   [0.433846 0.428571]\n","   ...\n","   [0.429538 0.467742]\n","   [0.435077 0.459016]\n","   [0.443077 0.423729]]]\n","\n","\n"," [[[0.248615 0.106383]\n","   [0.243692 0.083333]\n","   [0.24     0.0625  ]\n","   ...\n","   [0.253538 0.018519]\n","   [0.260308 0.      ]\n","   [0.267692 0.      ]]\n","\n","  [[0.246154 0.106383]\n","   [0.24     0.104167]\n","   [0.235077 0.0625  ]\n","   ...\n","   [0.244923 0.018519]\n","   [0.251692 0.      ]\n","   [0.259692 0.      ]]\n","\n","  [[0.243692 0.106383]\n","   [0.236308 0.104167]\n","   [0.230154 0.0625  ]\n","   ...\n","   [0.236308 0.      ]\n","   [0.243692 0.      ]\n","   [0.251692 0.      ]]\n","\n","  ...\n","\n","  [[0.302769 0.638298]\n","   [0.276923 0.583333]\n","   [0.254769 0.520833]\n","   ...\n","   [0.201231 0.407407]\n","   [0.214154 0.415094]\n","   [0.230154 0.431373]]\n","\n","  [[0.324923 0.702128]\n","   [0.297231 0.666667]\n","   [0.273231 0.625   ]\n","   ...\n","   [0.214769 0.481481]\n","   [0.227692 0.490566]\n","   [0.244923 0.509804]]\n","\n","  [[0.349538 0.765957]\n","   [0.321846 0.75    ]\n","   [0.296    0.708333]\n","   ...\n","   [0.232615 0.555556]\n","   [0.246154 0.566038]\n","   [0.264615 0.588235]]]\n","\n","\n"," ...\n","\n","\n"," [[[0.931077 0.305556]\n","   [0.933538 0.315068]\n","   [0.931692 0.328767]\n","   ...\n","   [0.930462 0.422535]\n","   [0.931077 0.416667]\n","   [0.931692 0.430556]]\n","\n","  [[0.933538 0.305556]\n","   [0.933538 0.315068]\n","   [0.933538 0.315068]\n","   ...\n","   [0.932923 0.352113]\n","   [0.934154 0.361111]\n","   [0.934154 0.361111]]\n","\n","  [[0.935385 0.319444]\n","   [0.934154 0.328767]\n","   [0.933538 0.315068]\n","   ...\n","   [0.933538 0.28169 ]\n","   [0.933538 0.305556]\n","   [0.935385 0.305556]]\n","\n","  ...\n","\n","  [[0.930462 0.277778]\n","   [0.931692 0.30137 ]\n","   [0.932923 0.342466]\n","   ...\n","   [0.917538 0.295775]\n","   [0.921846 0.222222]\n","   [0.925538 0.152778]]\n","\n","  [[0.929846 0.375   ]\n","   [0.933538 0.383562]\n","   [0.933538 0.39726 ]\n","   ...\n","   [0.921846 0.309859]\n","   [0.921231 0.263889]\n","   [0.922462 0.194444]]\n","\n","  [[0.933538 0.430556]\n","   [0.937231 0.424658]\n","   [0.936615 0.424658]\n","   ...\n","   [0.923077 0.323944]\n","   [0.920615 0.291667]\n","   [0.921846 0.25    ]]]\n","\n","\n"," [[[0.868923 0.603774]\n","   [0.875077 0.509091]\n","   [0.88     0.413793]\n","   ...\n","   [0.862154 0.      ]\n","   [0.858462 0.      ]\n","   [0.855385 0.      ]]\n","\n","  [[0.879385 0.54717 ]\n","   [0.884308 0.454545]\n","   [0.888    0.37931 ]\n","   ...\n","   [0.858462 0.014925]\n","   [0.855385 0.045455]\n","   [0.854154 0.079365]]\n","\n","  [[0.888615 0.509434]\n","   [0.891692 0.418182]\n","   [0.893538 0.327586]\n","   ...\n","   [0.856    0.089552]\n","   [0.854769 0.136364]\n","   [0.855385 0.174603]]\n","\n","  ...\n","\n","  [[0.900923 0.037736]\n","   [0.892308 0.      ]\n","   [0.884308 0.017241]\n","   ...\n","   [0.883692 0.402985]\n","   [0.888615 0.409091]\n","   [0.894769 0.380952]]\n","\n","  [[0.899077 0.018868]\n","   [0.891077 0.      ]\n","   [0.882462 0.034483]\n","   ...\n","   [0.891077 0.447761]\n","   [0.897231 0.454545]\n","   [0.904    0.428571]]\n","\n","  [[0.897846 0.018868]\n","   [0.889846 0.      ]\n","   [0.881846 0.051724]\n","   ...\n","   [0.898462 0.507463]\n","   [0.904    0.5     ]\n","   [0.913846 0.47619 ]]]\n","\n","\n"," [[[0.856    0.028986]\n","   [0.864    0.014706]\n","   [0.874462 0.058824]\n","   ...\n","   [0.897231 0.381818]\n","   [0.896615 0.418182]\n","   [0.895385 0.407407]]\n","\n","  [[0.852308 0.072464]\n","   [0.851692 0.044118]\n","   [0.856615 0.058824]\n","   ...\n","   [0.899077 0.363636]\n","   [0.900923 0.381818]\n","   [0.902154 0.388889]]\n","\n","  [[0.854154 0.188406]\n","   [0.855385 0.161765]\n","   [0.859077 0.161765]\n","   ...\n","   [0.905846 0.327273]\n","   [0.907692 0.345455]\n","   [0.907692 0.351852]]\n","\n","  ...\n","\n","  [[0.913231 0.478261]\n","   [0.916923 0.455882]\n","   [0.921231 0.441176]\n","   ...\n","   [0.931077 0.272727]\n","   [0.928615 0.236364]\n","   [0.924923 0.12963 ]]\n","\n","  [[0.918769 0.449275]\n","   [0.922462 0.426471]\n","   [0.925538 0.411765]\n","   ...\n","   [0.932308 0.254545]\n","   [0.929846 0.254545]\n","   [0.926154 0.203704]]\n","\n","  [[0.923077 0.42029 ]\n","   [0.926154 0.397059]\n","   [0.929231 0.382353]\n","   ...\n","   [0.933538 0.236364]\n","   [0.931077 0.254545]\n","   [0.927385 0.240741]]]]\n"]}],"source":["X_3D = X.to_numpy().reshape(X.shape[0], 15, 15, 2)\n","print(X_3D)"]},{"cell_type":"code","execution_count":null,"id":"6575ce80","metadata":{"id":"6575ce80","outputId":"187493aa-57de-4844-ff48-987111bf0b17"},"outputs":[{"name":"stdout","output_type":"stream","text":["(515, 15, 15, 2) (515,) (222, 15, 15, 2) (222,)\n"]}],"source":["# train and test split\n","train_x, test_x, train_y, test_y = train_test_split(X_3D, Y_numerized, test_size=0.3, random_state=42)\n","print(train_x.shape, train_y.shape, test_x.shape, test_y.shape) # check the shapes"]},{"cell_type":"code","execution_count":null,"id":"647e32ba","metadata":{"scrolled":true,"id":"647e32ba"},"outputs":[],"source":["model = Sequential()\n","model.add(Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=(15,15,2)))\n","model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","#model.add(Dense(128, activation='relu'))\n","#model.add(Dense(64, activation='relu'))\n","model.add(Dense(4, activation='softmax'))\n","\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"id":"d99f8968","metadata":{"scrolled":true,"id":"d99f8968","outputId":"05028084-8d6a-465d-b1f8-5637c715a80f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/1000\n","17/17 [==============================] - 2s 16ms/step - loss: 1.2245 - accuracy: 0.4796\n","Epoch 2/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.8427 - accuracy: 0.7282\n","Epoch 3/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.5769 - accuracy: 0.7670\n","Epoch 4/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.5348 - accuracy: 0.7767\n","Epoch 5/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.4842 - accuracy: 0.8019\n","Epoch 6/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.4699 - accuracy: 0.8078\n","Epoch 7/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.4888 - accuracy: 0.7942\n","Epoch 8/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.4683 - accuracy: 0.8097\n","Epoch 9/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.4370 - accuracy: 0.8058\n","Epoch 10/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.4368 - accuracy: 0.8039\n","Epoch 11/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.4427 - accuracy: 0.7903\n","Epoch 12/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.4203 - accuracy: 0.8252\n","Epoch 13/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.3964 - accuracy: 0.8369\n","Epoch 14/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.3987 - accuracy: 0.8194\n","Epoch 15/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.3918 - accuracy: 0.8136\n","Epoch 16/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.3747 - accuracy: 0.8291\n","Epoch 17/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.3894 - accuracy: 0.8330\n","Epoch 18/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.3936 - accuracy: 0.8272\n","Epoch 19/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.4051 - accuracy: 0.8058\n","Epoch 20/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.3701 - accuracy: 0.8388\n","Epoch 21/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.3887 - accuracy: 0.8194\n","Epoch 22/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.3686 - accuracy: 0.8369\n","Epoch 23/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.3815 - accuracy: 0.8252\n","Epoch 24/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.3628 - accuracy: 0.8330\n","Epoch 25/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.3836 - accuracy: 0.8233\n","Epoch 26/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.3587 - accuracy: 0.8350\n","Epoch 27/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.3579 - accuracy: 0.8330\n","Epoch 28/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.3523 - accuracy: 0.8447\n","Epoch 29/1000\n","17/17 [==============================] - 0s 17ms/step - loss: 0.3651 - accuracy: 0.8214\n","Epoch 30/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.3505 - accuracy: 0.8505\n","Epoch 31/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.3418 - accuracy: 0.8330\n","Epoch 32/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.3320 - accuracy: 0.8369\n","Epoch 33/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.3338 - accuracy: 0.8447\n","Epoch 34/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.3669 - accuracy: 0.8330\n","Epoch 35/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.3407 - accuracy: 0.8621\n","Epoch 36/1000\n","17/17 [==============================] - 0s 17ms/step - loss: 0.3413 - accuracy: 0.8388\n","Epoch 37/1000\n","17/17 [==============================] - 0s 17ms/step - loss: 0.3291 - accuracy: 0.8427\n","Epoch 38/1000\n","17/17 [==============================] - 0s 17ms/step - loss: 0.3294 - accuracy: 0.8621\n","Epoch 39/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.3200 - accuracy: 0.8757\n","Epoch 40/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.3383 - accuracy: 0.8388\n","Epoch 41/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.3334 - accuracy: 0.8485\n","Epoch 42/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.3063 - accuracy: 0.8563\n","Epoch 43/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.3512 - accuracy: 0.8291\n","Epoch 44/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.3142 - accuracy: 0.8544\n","Epoch 45/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.3229 - accuracy: 0.8505\n","Epoch 46/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.3518 - accuracy: 0.8485\n","Epoch 47/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.3182 - accuracy: 0.8621\n","Epoch 48/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.3063 - accuracy: 0.8738\n","Epoch 49/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.3077 - accuracy: 0.8485\n","Epoch 50/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.3528 - accuracy: 0.8369\n","Epoch 51/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.3066 - accuracy: 0.8447\n","Epoch 52/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.3405 - accuracy: 0.8447\n","Epoch 53/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.2987 - accuracy: 0.8602\n","Epoch 54/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.3216 - accuracy: 0.8583\n","Epoch 55/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.3323 - accuracy: 0.8466\n","Epoch 56/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.3568 - accuracy: 0.8408\n","Epoch 57/1000\n","17/17 [==============================] - 0s 17ms/step - loss: 0.3404 - accuracy: 0.8311\n","Epoch 58/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.3050 - accuracy: 0.8602\n","Epoch 59/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.3076 - accuracy: 0.8680\n","Epoch 60/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.3153 - accuracy: 0.8641\n","Epoch 61/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.3200 - accuracy: 0.8602\n","Epoch 62/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.3139 - accuracy: 0.8621\n","Epoch 63/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2917 - accuracy: 0.8680\n","Epoch 64/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2939 - accuracy: 0.8583\n","Epoch 65/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.3053 - accuracy: 0.8660\n","Epoch 66/1000\n","17/17 [==============================] - 0s 17ms/step - loss: 0.2899 - accuracy: 0.8757\n","Epoch 67/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.3048 - accuracy: 0.8680\n","Epoch 68/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.3097 - accuracy: 0.8602\n","Epoch 69/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2946 - accuracy: 0.8777\n","Epoch 70/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2792 - accuracy: 0.8699\n","Epoch 71/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2942 - accuracy: 0.8699\n","Epoch 72/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2794 - accuracy: 0.8796\n","Epoch 73/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.3016 - accuracy: 0.8718\n","Epoch 74/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2652 - accuracy: 0.8854\n","Epoch 75/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2874 - accuracy: 0.8816\n","Epoch 76/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2774 - accuracy: 0.8854\n","Epoch 77/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.3072 - accuracy: 0.8660\n","Epoch 78/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.3433 - accuracy: 0.8524\n","Epoch 79/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2726 - accuracy: 0.8796\n","Epoch 80/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2784 - accuracy: 0.8738\n","Epoch 81/1000\n"]},{"name":"stdout","output_type":"stream","text":["17/17 [==============================] - 0s 15ms/step - loss: 0.2821 - accuracy: 0.8816\n","Epoch 82/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2673 - accuracy: 0.8777\n","Epoch 83/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2764 - accuracy: 0.8796\n","Epoch 84/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2846 - accuracy: 0.8680\n","Epoch 85/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2687 - accuracy: 0.8874\n","Epoch 86/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2709 - accuracy: 0.8854\n","Epoch 87/1000\n","17/17 [==============================] - 0s 17ms/step - loss: 0.3186 - accuracy: 0.8505\n","Epoch 88/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.3091 - accuracy: 0.8680\n","Epoch 89/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2691 - accuracy: 0.8971\n","Epoch 90/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2833 - accuracy: 0.8796\n","Epoch 91/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2732 - accuracy: 0.8874\n","Epoch 92/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2801 - accuracy: 0.8816\n","Epoch 93/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2884 - accuracy: 0.8660\n","Epoch 94/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2902 - accuracy: 0.8777\n","Epoch 95/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2730 - accuracy: 0.8816\n","Epoch 96/1000\n","17/17 [==============================] - 0s 17ms/step - loss: 0.2618 - accuracy: 0.8796\n","Epoch 97/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2763 - accuracy: 0.8757\n","Epoch 98/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2970 - accuracy: 0.8621\n","Epoch 99/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2579 - accuracy: 0.8913\n","Epoch 100/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2967 - accuracy: 0.8738\n","Epoch 101/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2634 - accuracy: 0.8835\n","Epoch 102/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2588 - accuracy: 0.8932\n","Epoch 103/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.3165 - accuracy: 0.8699\n","Epoch 104/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2790 - accuracy: 0.8699\n","Epoch 105/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2617 - accuracy: 0.8874\n","Epoch 106/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2430 - accuracy: 0.9029\n","Epoch 107/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2546 - accuracy: 0.9068\n","Epoch 108/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2903 - accuracy: 0.8816\n","Epoch 109/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2657 - accuracy: 0.8913\n","Epoch 110/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2691 - accuracy: 0.8854\n","Epoch 111/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2722 - accuracy: 0.8874\n","Epoch 112/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2446 - accuracy: 0.9010\n","Epoch 113/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2556 - accuracy: 0.8893\n","Epoch 114/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2704 - accuracy: 0.8854\n","Epoch 115/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2416 - accuracy: 0.8990\n","Epoch 116/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2673 - accuracy: 0.9049\n","Epoch 117/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2423 - accuracy: 0.9126\n","Epoch 118/1000\n","17/17 [==============================] - 0s 13ms/step - loss: 0.2466 - accuracy: 0.8990\n","Epoch 119/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2252 - accuracy: 0.9107\n","Epoch 120/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.2323 - accuracy: 0.9068\n","Epoch 121/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2458 - accuracy: 0.9049\n","Epoch 122/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2230 - accuracy: 0.9165\n","Epoch 123/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2177 - accuracy: 0.9010\n","Epoch 124/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2359 - accuracy: 0.8893\n","Epoch 125/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2428 - accuracy: 0.9049\n","Epoch 126/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2272 - accuracy: 0.9068\n","Epoch 127/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2171 - accuracy: 0.9126\n","Epoch 128/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2254 - accuracy: 0.8990\n","Epoch 129/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2270 - accuracy: 0.8990\n","Epoch 130/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2410 - accuracy: 0.9029\n","Epoch 131/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2425 - accuracy: 0.8854\n","Epoch 132/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2328 - accuracy: 0.9087\n","Epoch 133/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.2387 - accuracy: 0.9184\n","Epoch 134/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2551 - accuracy: 0.8893\n","Epoch 135/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2313 - accuracy: 0.9146\n","Epoch 136/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2105 - accuracy: 0.9068\n","Epoch 137/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2540 - accuracy: 0.8874\n","Epoch 138/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2127 - accuracy: 0.9107\n","Epoch 139/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2277 - accuracy: 0.9029\n","Epoch 140/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2180 - accuracy: 0.9184\n","Epoch 141/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2184 - accuracy: 0.9146\n","Epoch 142/1000\n","17/17 [==============================] - 0s 17ms/step - loss: 0.2040 - accuracy: 0.9243\n","Epoch 143/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2285 - accuracy: 0.9107\n","Epoch 144/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2140 - accuracy: 0.9146\n","Epoch 145/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.1958 - accuracy: 0.9184\n","Epoch 146/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2226 - accuracy: 0.9126\n","Epoch 147/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.2050 - accuracy: 0.9146\n","Epoch 148/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.1957 - accuracy: 0.9184\n","Epoch 149/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2068 - accuracy: 0.9204\n","Epoch 150/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2270 - accuracy: 0.8932\n","Epoch 151/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2345 - accuracy: 0.9087\n","Epoch 152/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2023 - accuracy: 0.9107\n","Epoch 153/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2318 - accuracy: 0.9049\n","Epoch 154/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.1962 - accuracy: 0.9320\n","Epoch 155/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.1886 - accuracy: 0.9184\n","Epoch 156/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2235 - accuracy: 0.9204\n","Epoch 157/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2321 - accuracy: 0.9049\n","Epoch 158/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.2127 - accuracy: 0.9204\n","Epoch 159/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2738 - accuracy: 0.8932\n","Epoch 160/1000\n"]},{"name":"stdout","output_type":"stream","text":["17/17 [==============================] - 0s 14ms/step - loss: 0.2179 - accuracy: 0.9010\n","Epoch 161/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2175 - accuracy: 0.9126\n","Epoch 162/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.1985 - accuracy: 0.9320\n","Epoch 163/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.1975 - accuracy: 0.9184\n","Epoch 164/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.1949 - accuracy: 0.9184\n","Epoch 165/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2146 - accuracy: 0.9087\n","Epoch 166/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2262 - accuracy: 0.9029\n","Epoch 167/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.1892 - accuracy: 0.9282\n","Epoch 168/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.2153 - accuracy: 0.8951\n","Epoch 169/1000\n","17/17 [==============================] - 0s 18ms/step - loss: 0.1943 - accuracy: 0.9262\n","Epoch 170/1000\n","17/17 [==============================] - 0s 17ms/step - loss: 0.1691 - accuracy: 0.9359\n","Epoch 171/1000\n","17/17 [==============================] - 0s 18ms/step - loss: 0.2144 - accuracy: 0.9165\n","Epoch 172/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2010 - accuracy: 0.9223\n","Epoch 173/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.1829 - accuracy: 0.9223\n","Epoch 174/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.1865 - accuracy: 0.9359\n","Epoch 175/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.1718 - accuracy: 0.9379\n","Epoch 176/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.1861 - accuracy: 0.9320\n","Epoch 177/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.1932 - accuracy: 0.9146\n","Epoch 178/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.1982 - accuracy: 0.9184\n","Epoch 179/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2041 - accuracy: 0.9146\n","Epoch 180/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2536 - accuracy: 0.8738\n","Epoch 181/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2044 - accuracy: 0.9087\n","Epoch 182/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2021 - accuracy: 0.9107\n","Epoch 183/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.1797 - accuracy: 0.9301\n","Epoch 184/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.1717 - accuracy: 0.9340\n","Epoch 185/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2225 - accuracy: 0.9068\n","Epoch 186/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2141 - accuracy: 0.9165\n","Epoch 187/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.2083 - accuracy: 0.9126\n","Epoch 188/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.2076 - accuracy: 0.9087\n","Epoch 189/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.1605 - accuracy: 0.9379\n","Epoch 190/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.1954 - accuracy: 0.9184\n","Epoch 191/1000\n","17/17 [==============================] - 0s 17ms/step - loss: 0.1584 - accuracy: 0.9340\n","Epoch 192/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.2209 - accuracy: 0.9010\n","Epoch 193/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.2618 - accuracy: 0.8835\n","Epoch 194/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.1789 - accuracy: 0.9262\n","Epoch 195/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.1903 - accuracy: 0.9126\n","Epoch 196/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.1816 - accuracy: 0.9223\n","Epoch 197/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.1848 - accuracy: 0.9146\n","Epoch 198/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.1770 - accuracy: 0.9398\n","Epoch 199/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.3998 - accuracy: 0.8602\n","Epoch 200/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.2252 - accuracy: 0.9068\n","Epoch 201/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.1907 - accuracy: 0.9243\n","Epoch 202/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.1786 - accuracy: 0.9359\n","Epoch 203/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.1611 - accuracy: 0.9417\n","Epoch 204/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.1616 - accuracy: 0.9417\n","Epoch 205/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.1594 - accuracy: 0.9359\n","Epoch 206/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.1684 - accuracy: 0.9476\n","Epoch 207/1000\n","17/17 [==============================] - 0s 19ms/step - loss: 0.1593 - accuracy: 0.9379\n","Epoch 208/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.1552 - accuracy: 0.9534\n","Epoch 209/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.1358 - accuracy: 0.9456\n","Epoch 210/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.1794 - accuracy: 0.9223\n","Epoch 211/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.1699 - accuracy: 0.9359\n","Epoch 212/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.1690 - accuracy: 0.9379\n","Epoch 213/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.1470 - accuracy: 0.9476\n","Epoch 214/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.1402 - accuracy: 0.9495\n","Epoch 215/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.1546 - accuracy: 0.9456\n","Epoch 216/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.1427 - accuracy: 0.9398\n","Epoch 217/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.1466 - accuracy: 0.9476\n","Epoch 218/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.1450 - accuracy: 0.9476\n","Epoch 219/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.1783 - accuracy: 0.9301\n","Epoch 220/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.1439 - accuracy: 0.9476\n","Epoch 221/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.1520 - accuracy: 0.9398\n","Epoch 222/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.1399 - accuracy: 0.9417\n","Epoch 223/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.1707 - accuracy: 0.9243\n","Epoch 224/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.1543 - accuracy: 0.9417\n","Epoch 225/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.1521 - accuracy: 0.9340\n","Epoch 226/1000\n","17/17 [==============================] - 0s 14ms/step - loss: 0.1640 - accuracy: 0.9417\n","Epoch 227/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.1962 - accuracy: 0.9243\n","Epoch 228/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.1652 - accuracy: 0.9340\n","Epoch 229/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.1373 - accuracy: 0.9476\n","Epoch 230/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.1635 - accuracy: 0.9320\n","Epoch 231/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.1689 - accuracy: 0.9359\n","Epoch 232/1000\n","17/17 [==============================] - 0s 17ms/step - loss: 0.1575 - accuracy: 0.9379\n","Epoch 233/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.1490 - accuracy: 0.9437\n","Epoch 234/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.1580 - accuracy: 0.9398\n","Epoch 235/1000\n","17/17 [==============================] - 0s 15ms/step - loss: 0.1611 - accuracy: 0.9301\n","Epoch 236/1000\n","17/17 [==============================] - 0s 17ms/step - loss: 0.1531 - accuracy: 0.9379\n","Epoch 237/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.1419 - accuracy: 0.9398\n","Epoch 238/1000\n","17/17 [==============================] - 0s 16ms/step - loss: 0.1435 - accuracy: 0.9476\n","Epoch 239/1000\n"]},{"name":"stdout","output_type":"stream","text":["17/17 [==============================] - 0s 14ms/step - loss: 0.1428 - accuracy: 0.9417\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x2d0c0919850>"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# Train the model\n","early_stopping = EarlyStopping(monitor='loss', patience=30)\n","tensorboard_callback = TensorBoard(log_dir=\"./logs\")\n","model.fit(train_x, train_y, epochs=1000, batch_size=32, callbacks=[tensorboard_callback, early_stopping])"]},{"cell_type":"code","execution_count":null,"id":"1b7c5822","metadata":{"id":"1b7c5822","outputId":"b72a5460-3022-4643-b307-9acbae3b39e2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test accuracy: 0.8603603603603603\n"]}],"source":["# Use the trained model to make predictions on the test set\n","y_pred = model.predict(test_x).argmax(axis=1)\n","\n","# Calculate the accuracy of the model on the test set\n","accuracy = accuracy_score(test_y, y_pred)\n","print('Test accuracy:', accuracy)"]},{"cell_type":"code","execution_count":null,"id":"a8037d73","metadata":{"id":"a8037d73","outputId":"a44ca5fc-5460-43dd-fb05-d0fb1ba55d17"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[47  0 11  0]\n"," [ 0 12  7  2]\n"," [ 6  1 84  1]\n"," [ 0  1  2 48]]\n"]}],"source":["cm = confusion_matrix(test_y, y_pred)\n","print(cm)"]},{"cell_type":"markdown","id":"0c145702","metadata":{"id":"0c145702"},"source":["model.add(Conv2D(filters=128, kernel_size=3, activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.25))"]},{"cell_type":"code","execution_count":null,"id":"1af02d77","metadata":{"id":"1af02d77"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}